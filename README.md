# Privacy Does Not Work: A Sample Reconstruction Attack against Federated Learning with Differential Privacy

**The implementation of paper:<br>
Privacy Does Not Work: A Sample Reconstruction Attack against Federated Learning with Differential Privacy**

We propose an attack against federated learning (FL) with differential privacy (DP) in which gradients uploaded by
users are clipped and perturbed.

Here are some examples:

Original samples:
![original.png](fig%2Foriginal.png)

Our reconstructed samples:
![res.png](fig%2Fres.png)

Reconstructed samples generated by other attacks:
![when.png](fig%2Fwhen.png)

Other attacks are implemented by Jonas Geiping. If you are interested in more reconstruction samples in FL, please check
out his project: https://github.com/JonasGeiping/breaching